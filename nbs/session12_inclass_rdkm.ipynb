{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 12 - Measuring environmental impact\n",
    "\n",
    "In this session, we're going to look at one particular way that we can measure the impact of our code on the world around us. In particular, we're going to be looking at how we can approximate the *environmental impact* of our cultural data science footprint.\n",
    "\n",
    "To do this, we're going to use the open-source software package *CodeCarbon*. You can find more information at the following links:\n",
    "\n",
    "- CodeCarbon Website: [https://codecarbon.io/](https://codecarbon.io/)\n",
    "- GitHub Repo: [https://mlco2.github.io/codecarbon/](https://mlco2.github.io/codecarbon/)\n",
    "- Documentation: [https://mlco2.github.io/codecarbon/](https://mlco2.github.io/codecarbon/)\n",
    "\n",
    "We'll do some testing on HuggingFace pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing HuggingFace pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from codecarbon import EmissionsTracker\n",
    "from transformers import pipeline\n",
    "import datasets\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Text summarization pipeline__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may remember from a couple of weeks ago that *text summarization* was quite a compute intensive task. So let's see exactly how compute intensive it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. \n",
    "For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. \n",
    "On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. \n",
    "In the former task our best model outperforms even all previously reported ensembles.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(task=\"summarization\", \n",
    "                      min_length=10,\n",
    "                      max_length=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of different ways that we can work with CodeCarbon, all of which is clearly explained in the relevant documentation.\n",
    "\n",
    "We'll go through each of them one at a time here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1 - Creating a tracker object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = EmissionsTracker()\n",
    "tracker.start()\n",
    "summary = summarizer(text)\n",
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2 - Context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with EmissionsTracker() as tracker:\n",
    "    summary = summarizer(text)\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3 - A Python decoractor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codecarbon import track_emissions\n",
    "\n",
    "@track_emissions\n",
    "def summarization(text):\n",
    "    summary = summarizer(text)\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more complex example\n",
    "\n",
    "We can make the results more useful by changing the tracker parameters - full list can be found here [https://mlco2.github.io/codecarbon/parameters.html](https://mlco2.github.io/codecarbon/parameters.html).\n",
    "\n",
    "In the example that follows, we're going to download a HuggingFace dataset and a pretrained emotion classification model. \n",
    "\n",
    "We also introduce specific *tasks* to more clearly understand the impact of different parts of our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfolder = os.path.join(\"..\", \"emissions\")\n",
    "os.mkdir(outfolder)\n",
    "\n",
    "tracker = EmissionsTracker(project_name=\"sentiment classification\",\n",
    "                           experiment_id=\"sentiment_classifier\",\n",
    "                           output_dir=outfolder,\n",
    "                           output_file=\"emissions_sentiment.csv\")\n",
    "\n",
    "# tracking data downloading\n",
    "tracker.start_task(\"load dataset\")\n",
    "dataset = datasets.load_dataset(\"imdb\", \n",
    "                                split=\"test\")\n",
    "imdb_emissions = tracker.stop_task()\n",
    "\n",
    "# tracking downloading and initializing model\n",
    "tracker.start_task(\"build model\")\n",
    "classifier = pipeline(task=\"sentiment-analysis\", \n",
    "                      model=\"cardiffnlp/twitter-roberta-base-emotion\")\n",
    "model_emissions = tracker.stop_task()\n",
    "\n",
    "# tracking classification pipeline\n",
    "tracker.start_task(\"run classification\")\n",
    "preds = []\n",
    "for row in tqdm(dataset[\"text\"][:1000]):\n",
    "    preds.append(classifier(row[:100]))\n",
    "classifier_emissions = tracker.stop_task()\n",
    "\n",
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Inspecting the results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_df = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "- Now that you have the basics down, head over and consider Assignment 5!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
